## [2013 - Stochastic gradient descent on Riemannian manifolds](https://ieeexplore.ieee.org/abstract/document/6487381/)

+ 贡献：we develop a procedure **extending stochastic gradient descent algorithms** to the case where the **function is defined on a Riemannian manifold**.

  + 介绍**general stochastic gradient descent algorithms** on Riemannian manifolds。可归类到本文提出的一般框架中去。
  + 分析**convergence** properties of the algorithms；
  + 应用示例applied to four examples。Oja algorithm（PCA）、

+ $R^N$里的标准SGD的不足：比如low-rank matrix estimation ( matrix completion）问题，如解决CF问题，方法是：is to constrain the state space by assuming the tastes of the users are explained **by a reduced number of criteria**(say, r). 则问题解为non-linear optimization problem；

  ![image-20210321142013524](论文笔记/image-20210321142013524.png)

  <font color='red'>**但是求的解不能保证是rank r的** </font>，the updated matrix $W − γ_t∇W(W^*_{ij} − W_{ij})^2$ does not have rank r。解决办法是to enforce the rank constraint is to **endow the parameter space with a Riemannian metric**.

+ 黎曼流形里的SGD方法：参数w属于黎曼流形里，替代更新规则：其中

  ![image-20210321140542872](论文笔记/image-20210321140542872.png)

  其中$exp_{w_t}$为w点的exponential map函数。从黎曼流形映射到其切空间（欧几里得）。

+ 参数收敛：The parameter is proved to **converge almost surely to a critical point of the cost function** in various cases and under various conditions，以下两种情况之一，参数完全收敛。

  + when the parameter $w\in M$ is proved to remain in a **compact set**,

  + on specific non positively curved Riemannian manifolds，a slightly modified。具体请看文件。

未完，



## [2014 - SIGKDD - Deepwalk: Online learning of social representations](https://dl.acm.org/doi/abs/10.1145/2623330.2623732)

+ 思路：使用随机游走产生局部信息学习节点的潜在表示，uses **local information obtained from truncated random walks** to learn **latent representations** by **treating walks as the equivalent of sentences**。
+ 优点
  + local exploration is easy to **parallelize**. 
  + accommodate **small changes** in the graph structure **without the need for global recomputation**.
+ 方法：将随机游走产生的序列当作NLP里的句子，因此可以使用NLP里的：
  + **CBOW**：using the context to predict a missing word。
  + **SkipGram**：uses one word to predict the context。文章使用的方法。





## [2017 - Poincar\'e embeddings for learning hierarchical representations](https://arxiv.org/abs/1705.08039)

+ 动机：complex symbolic datasets often exhibit a latent **hierarchical structure**。比如power-law distributions in datasets（social and semantic networks） can often be traced back to hierarchical structures，
  
+ 贡献：introduce a new approach for **learning hierarchical representations of symbolic data by embedding them into hyperbolic space**（n-dimensional Poincaré ball）。

+ Poincaré Embeddings：

  + 定义各符号数据位于open d-dimensional unit ball：$B^d = \{x \in R^d |\ ||x|| < 1\}$空间中，equipped with the Riemannian metric tensor，

    ![image-20210321151538815](论文笔记/image-20210321151538815.png)

    其中$g^E$为欧几里得度量[1,……,1]。流形空间里两点的距离为：

    ![image-20210321151716372](论文笔记/image-20210321151716372.png)

  + 使用多维：

    1. **multiple latent hierarchies can co-exist**, which can not always be modeled in two dimensions. 
    2.  a larger embedding dimension can **decrease the difficulty** for an optimization method to find a good embedding。

  + 损失函数：$L(\Theta)$encourages semantically **similar objects to be close** in the embedding space according to **their Poincaré distance**。

    ![image-20210321153132975](论文笔记/image-20210321153132975.png)

+ 优化方法：使用黎曼流形里的随机梯度下降RSGD：

  ![image-20210321152358034](论文笔记/image-20210321152358034.png)
  
  最后使用的是：
  
  ![image-20210321154831117](论文笔记/image-20210321154831117.png)

具体推导看论文



## [2018 - NIPS - Hyperbolic neural networks](https://arxiv.org/abs/1805.09112)

+ 贡献：基于双曲空间的方法比欧几里得空间的少，是因为双曲空间中缺少了对应的hyperbolic neural network layers；generalize deep neural models to non-Euclidean domains 。**derive hyperbolic versions of important deep learning tools**（multinomial logistic regression (MLR), feed-forward (FFNN), simple and gated (GRU) recurrent neural networks (RNN)）。

未完





## [2019 - ICLR - Rotate: Knowledge graph embedding by relational rotation in complex space](https://arxiv.org/abs/1902.10197)

+ 贡献：present a new approach for knowledge graph embedding，to model and infer various **relation patterns** including: **symmetry/antisymmetry, inversion, and composition**。and a novel self-adversarial negative sampling technique。

  + 比如symmetry（e.g., marriage）、antisymmetric (e.g., filiation)；inverse of other relations (e.g., hypernym and hyponym); and some relations may be composed by others (e.g., my mother’s husband is my father).

+ 灵感来源：from Euler’s identity $e^{i\theta} = \cos\theta + i\sin\theta$，**unitary complex number can be regarded as a rotation in the complex plane**，复数的乘积可表示为：**相角相加，幅度相乘**

+ 方法：the RotatE model maps the entities and relations to the complex vector space and **defines each relation as a rotation from the source entity to the target entity**。Given a triplet ($h,r,t)$, we expect that $t = h \circ r$。

  ![image-20210322000515059](论文笔记/image-20210322000515059.png)

  三种关系间的联系可表示为：对称——$r=\pm 1$，反转——$r_1=\bar r_2$共轭，组合——$r_3=r_1\circ r_2$；

  ![image-20210322003743656](论文笔记/image-20210322003743656.png)

+ 与其他模型的比较：如transE是对inversion, and composition的建模。无法对对称建模，因为对称关系会为0，

  ![image-20210322004649992](论文笔记/image-20210322004649992.png)

+ 优化：以前uniform的采样的缺点：since **many samples are obviously false as training goes on**, which does not provide any meaningful information.提出了self-adversarial negative sampling, samples negative triples according to the current embedding model.

  ![image-20210322005614343](论文笔记/image-20210322005614343.png)

+ 损失函数：

  ![image-20210322005433452](论文笔记/image-20210322005433452.png)



## [2019 -  NIPS - Hyperbolic graph neural networks](https://arxiv.org/abs/1910.12892)

+ 贡献：novel **GNN architecture for learning representations on Riemannian manifolds** with **differentiable exponential and logarithmic maps**.

  + 使用logarithmic map $\log_x$将节点映射到tangent space；
  + 使用exponential map $\exp_x$将节点映射回manifold

+ 方法：Since the **tangent space of a point on Riemannian manifolds always is Euclidean** (or a subset of Euclidean space), functions with trainable parameters are executed there. 

  ![image-20210322010623197](论文笔记/image-20210322010623197.png)

  + Euclidean Space：$\exp_x(v) = x + v$，$\log_x(y) = y - x$。

  + Poincaré Ball Model：

    ![image-20210322011501623](论文笔记/image-20210322011501623.png)

  + Lorentz Model：

    ![image-20210322011605575](论文笔记/image-20210322011605575.png)



## [2019 - WWW - Tag2vec: Learning tag representations in tag networks](https://dl.acm.org/doi/abs/10.1145/3308558.3313622)

+ 之前network embedding的缺点：ignore the abundant semantic and hierarchical information of tags. 

+ 方法：mixes nodes and tags into a **hybrid network**，define semantic distance as the **proximity between tags**，use parameterized **random walk**, to generate **context with semantic and hierarchical information of tags** adaptively. use **hyperbolic Skip-gram model** to express the complex hierarchical structure better with lower output dimensions.

  + 定义标签的社区A Ground-truth Community $C_t$ is the **set of nodes labeled by tag t** ；然后用社区表示标签间的距离The distance between tags is defined by the **relationship between their groundtruth communities**. 

    + Member Similarity：the ratio of the common members to all members of two tag;
    + Social Closeness：the ratio of the **connected edges** between members of two ground-truth communities to all
      their **inter-connected edges**。

  + 使用标签间的信息产生上下文generate the **context** with both member similarity and social closeness information between tags.

    + 两种游走策略：MS-driven walk；SC-driven walk.

    ![image-20210322013629140](论文笔记/image-20210322013629140.png)

    


